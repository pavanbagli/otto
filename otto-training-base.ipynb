{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4682810,"sourceType":"datasetVersion","datasetId":2713594}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q tensorflow-recommenders\n!pip install -q scann","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport zipfile\nimport json\nimport tensorflow as tf\nimport tensorflow_recommenders as tfrs\nfrom tqdm import tqdm\nfrom typing import Dict, Text","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:21.970284Z","iopub.execute_input":"2022-12-27T09:01:21.970878Z","iopub.status.idle":"2022-12-27T09:01:25.870115Z","shell.execute_reply.started":"2022-12-27T09:01:21.970821Z","shell.execute_reply":"2022-12-27T09:01:25.869156Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2022-12-27 09:01:21.996938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-27 09:01:23.202189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-12-27 09:01:23.202435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n2022-12-27 09:01:23.202451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}]},{"cell_type":"code","source":"print('TensorFlow version: {}'.format(tf.__version__))\nprint('TensorFlow Recommender version: {}'.format(tfrs.__version__))\nprint('TensorFlow Raking')\nprint('TensorFlow ScaNN')","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:28.184348Z","iopub.execute_input":"2022-12-27T09:01:28.184873Z","iopub.status.idle":"2022-12-27T09:01:28.193954Z","shell.execute_reply.started":"2022-12-27T09:01:28.184824Z","shell.execute_reply":"2022-12-27T09:01:28.193003Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"TensorFlow version: 2.11.0\nTensorFlow Recommender version: v0.7.2\nTensorFlow Raking\nTensorFlow ScaNN\n","output_type":"stream"}]},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/otto-train-tfrecord-file/kaggle/working'\nOUTPUT_DIR = '/kaggle/working/'\nTRAIN_FILE = f'{INPUT_DIR}/train.jsonl'\nTEST_FILE = f'{INPUT_DIR}/test.jsonl'\n\nMODEL_DIR = f'{OUTPUT_DIR}/serving_model'\nMODEL_DIR_SCAN = f'{MODEL_DIR}/ScaNN_Model'\nMODEL_DIR_NORM = f'{MODEL_DIR}/Norm_Model'\n\n!mkdir -p {MODEL_DIR}\n!mkdir -p {MODEL_DIR_SCAN}\n!mkdir -p {MODEL_DIR_NORM}","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:29.583611Z","iopub.execute_input":"2022-12-27T09:01:29.584710Z","iopub.status.idle":"2022-12-27T09:01:32.463480Z","shell.execute_reply.started":"2022-12-27T09:01:29.584662Z","shell.execute_reply":"2022-12-27T09:01:32.462112Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices(\"GPU\")\nif gpus:\n    # Create 2 virtual GPUs with 1GB memory each\n    try:\n        tf.config.set_logical_device_configuration(\n            gpus[0],\n            [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n             tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Virtual devices must be set before GPUs have been initialized\n        print('error')\n        print(e)\n\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:33.616173Z","iopub.execute_input":"2022-12-27T09:01:33.617036Z","iopub.status.idle":"2022-12-27T09:01:35.006409Z","shell.execute_reply.started":"2022-12-27T09:01:33.616990Z","shell.execute_reply":"2022-12-27T09:01:35.005316Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"1 Physical GPU, 2 Logical GPUs\nNumber of devices: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# tfrecord_files = []\n# for dirname, _, filenames in os.walk(INPUT_DIR):\n#     for filename in filenames:\n#         tfrecord_files.append(os.path.join(dirname, filename))\n#         break\n# print(tfrecord_files)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a description of the features.\nfeature_description = {\n    'session': tf.io.FixedLenFeature([], tf.int64),\n    'aid': tf.io.FixedLenFeature([], tf.int64),\n    'ts': tf.io.FixedLenFeature([], tf.int64),\n    'typ': tf.io.FixedLenFeature([], tf.int64),\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:45.847729Z","iopub.execute_input":"2022-12-27T09:01:45.848090Z","iopub.status.idle":"2022-12-27T09:01:45.855408Z","shell.execute_reply.started":"2022-12-27T09:01:45.848058Z","shell.execute_reply":"2022-12-27T09:01:45.853709Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"window_size = 500\n\ndef item2item(ds):\n    item1 = ds['aid'][0]\n    item2, idx, rating = tf.unique_with_counts(ds['aid'])\n    item1 = tf.repeat(item1, repeats=[len(item2)],axis=0)\n    return {\"item_A\" : tf.strings.as_string(item1), \"item_B\" : tf.strings.as_string(item2), \"rating\": tf.cast(rating,dtype=tf.float32)}\n\ndef unique_item(ds):\n    items, idx, count = tf.unique_with_counts(ds['item_B'])\n    return {\"items\" :  items}","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:48.354440Z","iopub.execute_input":"2022-12-27T09:01:48.354808Z","iopub.status.idle":"2022-12-27T09:01:48.361778Z","shell.execute_reply.started":"2022-12-27T09:01:48.354777Z","shell.execute_reply":"2022-12-27T09:01:48.360799Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    dataset = tf.data.Dataset.list_files(f'{INPUT_DIR}/train_chunk_0*')\n    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type='ZLIB'), num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description))\n    dataset = dataset.take(1000)\n    dataset = dataset.group_by_window(\n                        key_func=lambda x: x['session'],\n                        reduce_func=lambda key, dataset: dataset.batch(window_size),\n                        window_size=window_size)\n    dataset = dataset.map(item2item).flat_map(tf.data.Dataset.from_tensor_slices)\n    print(dataset.element_spec)\n    dataset = dataset.batch(batch_size=64, num_parallel_calls=tf.data.AUTOTUNE)\n    print(dataset.element_spec)\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    print(dataset.element_spec)\n\n    items = dataset.map(unique_item).flat_map((tf.data.Dataset.from_tensor_slices))\n    items = items.map(lambda x: x[\"items\"])\n    items = items.batch(64)\n    print(items.element_spec)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:51.065653Z","iopub.execute_input":"2022-12-27T09:01:51.066691Z","iopub.status.idle":"2022-12-27T09:01:51.391712Z","shell.execute_reply.started":"2022-12-27T09:01:51.066652Z","shell.execute_reply":"2022-12-27T09:01:51.390728Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'item_A': TensorSpec(shape=(), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(), dtype=tf.float32, name=None)}\n{'item_A': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}\n{'item_A': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}\nTensorSpec(shape=(None,), dtype=tf.string, name=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"# for element in dataset.take(2):\n#     print(element)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for element in items.take(2):\n#     print(element)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nitemlist_unique = np.unique(np.concatenate(list(items)))\n# print(len(itemlist_unique))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:54.638112Z","iopub.execute_input":"2022-12-27T09:01:54.638497Z","iopub.status.idle":"2022-12-27T09:01:54.798847Z","shell.execute_reply.started":"2022-12-27T09:01:54.638465Z","shell.execute_reply":"2022-12-27T09:01:54.797026Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"CPU times: user 161 ms, sys: 26 ms, total: 187 ms\nWall time: 154 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(itemlist_unique))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:57.087880Z","iopub.execute_input":"2022-12-27T09:01:57.089101Z","iopub.status.idle":"2022-12-27T09:01:57.096966Z","shell.execute_reply.started":"2022-12-27T09:01:57.089052Z","shell.execute_reply":"2022-12-27T09:01:57.096028Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"615\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = dataset.shuffle(1000, seed=42, reshuffle_each_iteration=False)\n\n#train_dataset = shuffled_dataset.take(2000)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:01:58.570339Z","iopub.execute_input":"2022-12-27T09:01:58.571022Z","iopub.status.idle":"2022-12-27T09:01:58.583970Z","shell.execute_reply.started":"2022-12-27T09:01:58.570986Z","shell.execute_reply":"2022-12-27T09:01:58.583004Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# A multitask Model\n\nThere are two critical parts to multi-task recommenders:\n\n* They optimize for two or more objectives, and so have two or more losses.\n* They share variables between the tasks, allowing for transfer learning.\nIn this tutorial, we will define our models as before, but instead of having a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches.\n\nThe user and movie models are as before:","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    class item2itemModel(tfrs.models.Model):\n        def __init__(self) -> None:\n            super().__init__()\n            embedding_dimension = 32\n            self.item_A_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.item_B_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.rating_model = tf.keras.Sequential([\n                tf.keras.layers.Dense(256, activation=\"relu\"),\n                tf.keras.layers.Dense(128, activation=\"relu\"),\n                tf.keras.layers.Dense(1),\n                ])\n\n            self.retrieval_task = tfrs.tasks.Retrieval(\n                loss=tf.keras.losses.CategoricalCrossentropy(),\n                metrics=tfrs.metrics.FactorizedTopK(\n                    candidates=items.map(self.item_B_model),\n                    )\n                )\n\n            self.rating_task = tfrs.tasks.Ranking(\n                loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE),\n                metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                )\n\n        def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n            item_A_embeddings = self.item_A_model(features[\"item_A\"])\n            item_B_embeddings = self.item_B_model(features[\"item_B\"])\n            predicted_ratings = self.rating_model((tf.concat([item_A_embeddings, item_B_embeddings], axis=1)))\n            \n            return (item_A_embeddings, item_B_embeddings, predicted_ratings)\n\n        def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n            label_ratings = features.pop(\"rating\")\n            item_A_embeddings, item_B_embeddings, predicted_ratings = self(features)\n            print('item_A_embeddings: ', item_A_embeddings.shape)\n            print('item_B_embeddings: ', item_B_embeddings.shape)\n            print('predicted_ratings: ', predicted_ratings.shape)\n            \n            if training:\n                rating_loss = self.rating_task(labels=label_ratings, predictions=predicted_ratings,compute_metrics=False)\n                retrieval_loss = self.retrieval_task(item_A_embeddings, item_B_embeddings,compute_metrics=False)\n            else:\n                rating_loss = self.rating_task(labels=label_ratings, predictions=predicted_ratings,compute_metrics=True)\n                retrieval_loss = self.retrieval_task(item_A_embeddings, item_B_embeddings,compute_metrics=True)\n            print('retrieval_loss: ', retrieval_loss)\n\n            return (retrieval_loss + rating_loss)       ","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:02:06.927028Z","iopub.execute_input":"2022-12-27T09:02:06.927421Z","iopub.status.idle":"2022-12-27T09:02:06.940708Z","shell.execute_reply.started":"2022-12-27T09:02:06.927382Z","shell.execute_reply":"2022-12-27T09:02:06.939506Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = item2itemModel()\n    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:02:08.892401Z","iopub.execute_input":"2022-12-27T09:02:08.893431Z","iopub.status.idle":"2022-12-27T09:02:09.083938Z","shell.execute_reply.started":"2022-12-27T09:02:08.893383Z","shell.execute_reply":"2022-12-27T09:02:09.082976Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    cached_train = train_dataset.shuffle(1000).cache()\n    cached_test = train_dataset.shuffle(1000).batch(128).cache()\n\n    print(cached_train.element_spec)\n    print(cached_test.element_spec)\n    print(dataset.element_spec)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:02:14.542416Z","iopub.execute_input":"2022-12-27T09:02:14.543395Z","iopub.status.idle":"2022-12-27T09:02:14.560046Z","shell.execute_reply.started":"2022-12-27T09:02:14.543335Z","shell.execute_reply":"2022-12-27T09:02:14.558901Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'item_A': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}\n{'item_A': TensorSpec(shape=(None, None), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(None, None), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(None, None), dtype=tf.float32, name=None)}\n{'item_A': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'item_B': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'rating': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}\n","output_type":"stream"}]},{"cell_type":"code","source":"    model.fit(cached_train, epochs=3)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T09:02:17.093891Z","iopub.execute_input":"2022-12-27T09:02:17.094239Z","iopub.status.idle":"2022-12-27T09:02:35.725998Z","shell.execute_reply.started":"2022-12-27T09:02:17.094210Z","shell.execute_reply":"2022-12-27T09:02:35.725075Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2022-12-27 09:02:17.128888: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:784] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"GroupByWindowDataset/_16\"\nop: \"GroupByWindowDataset\"\ninput: \"TakeDataset/_15\"\nattr {\n  key: \"Tkey_func_other_arguments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"Treduce_func_other_arguments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"Twindow_size_func_other_arguments\"\n  value {\n    list {\n    }\n  }\n}\nattr {\n  key: \"_cardinality\"\n  value {\n    i: -2\n  }\n}\nattr {\n  key: \"key_func\"\n  value {\n    func {\n      name: \"__inference_Dataset_group_by_window_key_func_wrapper_82\"\n    }\n  }\n}\nattr {\n  key: \"metadata\"\n  value {\n    s: \"\\n\\026GroupByWindowDataset:5\"\n  }\n}\nattr {\n  key: \"output_shapes\"\n  value {\n    list {\n      shape {\n        dim {\n          size: -1\n        }\n      }\n      shape {\n        dim {\n          size: -1\n        }\n      }\n      shape {\n        dim {\n          size: -1\n        }\n      }\n      shape {\n        dim {\n          size: -1\n        }\n      }\n    }\n  }\n}\nattr {\n  key: \"output_types\"\n  value {\n    list {\n      type: DT_INT64\n      type: DT_INT64\n      type: DT_INT64\n      type: DT_INT64\n    }\n  }\n}\nattr {\n  key: \"reduce_func\"\n  value {\n    func {\n      name: \"__inference_Dataset_group_by_window_lambda_90\"\n    }\n  }\n}\nattr {\n  key: \"window_size_func\"\n  value {\n    func {\n      name: \"__inference_Dataset_group_by_window_window_size_func_wrapper_95\"\n    }\n  }\n}\nexperimental_type {\n  type_id: TFT_PRODUCT\n  args {\n    type_id: TFT_DATASET\n    args {\n      type_id: TFT_PRODUCT\n      args {\n        type_id: TFT_TENSOR\n        args {\n          type_id: TFT_INT64\n        }\n      }\n      args {\n        type_id: TFT_TENSOR\n        args {\n          type_id: TFT_INT64\n        }\n      }\n      args {\n        type_id: TFT_TENSOR\n        args {\n          type_id: TFT_INT64\n        }\n      }\n      args {\n        type_id: TFT_TENSOR\n        args {\n          type_id: TFT_INT64\n        }\n      }\n    }\n  }\n}\n. Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\nitem_A_embeddings:  (None, 32)\nitem_B_embeddings:  (None, 32)\npredicted_ratings:  (None, 1)\nretrieval_loss:  Tensor(\"retrieval/Identity:0\", shape=(None,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\nitem_A_embeddings:  (None, 32)\nitem_B_embeddings:  (None, 32)\npredicted_ratings:  (None, 1)\nretrieval_loss:  Tensor(\"replica_1/retrieval/Identity:0\", shape=(None,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\nitem_A_embeddings:  (None, 32)\nitem_B_embeddings:  (None, 32)\npredicted_ratings:  (None, 1)\nretrieval_loss:  Tensor(\"retrieval/Identity:0\", shape=(None,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\nitem_A_embeddings:  (None, 32)\nitem_B_embeddings:  (None, 32)\npredicted_ratings:  (None, 1)\nretrieval_loss:  Tensor(\"replica_1/retrieval/Identity:0\", shape=(None,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:23.880044: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n2022-12-27 09:02:23.880471: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n2022-12-27 09:02:24.181402: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n2022-12-27 09:02:24.266125: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"      1/Unknown - 7s 7s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0156 - factorized_top_k/top_50_categorical_accuracy: 0.0625 - factorized_top_k/top_100_categorical_accuracy: 0.1406 - root_mean_squared_error: 2.5398 - loss: 28.0865 - regularization_loss: 0.0000e+00 - total_loss: 28.0865","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:24.737576: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n2022-12-27 09:02:24.743605: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"      3/Unknown - 8s 398ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0052 - factorized_top_k/top_10_categorical_accuracy: 0.0156 - factorized_top_k/top_50_categorical_accuracy: 0.0521 - factorized_top_k/top_100_categorical_accuracy: 0.1458 - root_mean_squared_error: 1.8627 - loss: 21.8183 - regularization_loss: 0.0000e+00 - total_loss: 21.8183","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:25.661445: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"      4/Unknown - 9s 426ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0117 - factorized_top_k/top_50_categorical_accuracy: 0.0391 - factorized_top_k/top_100_categorical_accuracy: 0.1172 - root_mean_squared_error: 1.6465 - loss: 20.6285 - regularization_loss: 0.0000e+00 - total_loss: 20.6285","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:26.142704: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"      6/Unknown - 9s 420ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0028 - factorized_top_k/top_10_categorical_accuracy: 0.0083 - factorized_top_k/top_50_categorical_accuracy: 0.0305 - factorized_top_k/top_100_categorical_accuracy: 0.1025 - root_mean_squared_error: 1.5711 - loss: 19.0526 - regularization_loss: 0.0000e+00 - total_loss: 19.0526","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:26.964644: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"     10/Unknown - 11s 391ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0178 - factorized_top_k/top_100_categorical_accuracy: 0.0843 - root_mean_squared_error: 2.3999 - loss: 26.2955 - regularization_loss: 0.0000e+00 - total_loss: 26.2955","output_type":"stream"},{"name":"stderr","text":"2022-12-27 09:02:28.381169: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\nYou may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n","output_type":"stream"},{"name":"stdout","text":"10/10 [==============================] - 11s 431ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0178 - factorized_top_k/top_100_categorical_accuracy: 0.0843 - root_mean_squared_error: 2.3999 - loss: 25.7471 - regularization_loss: 0.0000e+00 - total_loss: 25.7471\nEpoch 2/3\n10/10 [==============================] - 3s 317ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0065 - factorized_top_k/top_5_categorical_accuracy: 0.0340 - factorized_top_k/top_10_categorical_accuracy: 0.0600 - factorized_top_k/top_50_categorical_accuracy: 0.2237 - factorized_top_k/top_100_categorical_accuracy: 0.3177 - root_mean_squared_error: 1.8695 - loss: 16.5888 - regularization_loss: 0.0000e+00 - total_loss: 16.5888\nEpoch 3/3\n10/10 [==============================] - 3s 347ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0081 - factorized_top_k/top_5_categorical_accuracy: 0.0519 - factorized_top_k/top_10_categorical_accuracy: 0.0810 - factorized_top_k/top_50_categorical_accuracy: 0.2496 - factorized_top_k/top_100_categorical_accuracy: 0.3663 - root_mean_squared_error: 1.7001 - loss: 16.1243 - regularization_loss: 0.0000e+00 - total_loss: 16.1243\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f78e3c5bd90>"},"metadata":{}}]},{"cell_type":"code","source":"    metrics = model.evaluate(cached_test, return_dict=True)\n\n    print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n    print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    scann_index = tfrs.layers.factorized_top_k.ScaNN(model.item_A_model, k=50)\n    scann_index.index_from_dataset(\n      tf.data.Dataset.zip((items, items.map(model.item_B_model)))\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the index.\ntf.saved_model.save(\n      scann_index,\n      MODEL_DIR_SCAN,\n      options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n  )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.retrieval_task = tfrs.tasks.Retrieval()  # Removes the metrics.\nmodel.compile()\nmodel.save(MODEL_DIR_NORM)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model(MODEL_DIR_NORM)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r trainer.zip '/kaggle/working/serving_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get recommendations.\n_, rec_item = scann_index(tf.constant([\"421211\"]))\nprint(f\"Recommendations for user 42: {rec_item[0, :50]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ratings = {}\n\nfor item in rec_item[0].numpy():\n    A, B, test_ratings[item] = model({\n      \"item_A\": np.array([\"421211\"]),\n      \"item_B\": np.array([item])\n  })\n\nprint(\"Ratings:\")\nfor key, value in test_ratings.items():\n    print('key:', key, \"rating:\", value )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}