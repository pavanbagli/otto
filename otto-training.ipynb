{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q tensorflow-recommenders\n!pip install -q scann","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport os\nimport zipfile\nimport tensorflow as tf\nimport tensorflow_recommenders as tfrs\nfrom tqdm import tqdm\nfrom typing import Dict, Text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('TensorFlow version: {}'.format(tf.__version__))\nprint('TensorFlow Recommender version: {}'.format(tfrs.__version__))\nprint('TensorFlow Raking')\nprint('TensorFlow ScaNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = '/kaggle/input/otto-pp-train/otto_pp_train'\nITEM_DIR = '/kaggle/input/otto-preprocessed-items-1'\nOUTPUT_DIR = '/kaggle/working/'\nCHECK_DIR = '/kaggle/working/chkpt1'\n\n# MODEL_DIR = f'{OUTPUT_DIR}/serving_model'\n# MODEL_DIR_SCAN = f'{MODEL_DIR}/ScaNN_Model'\n# MODEL_DIR_NORM = f'{MODEL_DIR}/Norm_Model'\n\n# !mkdir -p {MODEL_DIR}\n# !mkdir -p {MODEL_DIR_SCAN}\n# !mkdir -p {MODEL_DIR_NORM}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices(\"GPU\")\nfor gpu in gpus:\n    print(gpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if gpus:\n    # Create 2 virtual GPUs with 1GB memory each\n    try:\n        tf.config.set_logical_device_configuration(\n            gpus[0],\n            [tf.config.LogicalDeviceConfiguration(memory_limit=4096),\n             tf.config.LogicalDeviceConfiguration(memory_limit=4096)])\n        \n        logical_gpus = tf.config.list_logical_devices(\"GPU\")\n        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n    \n    except RuntimeError as e:\n        # Virtual devices must be set before GPUs have been initialized\n        print('error')\n        print(e)\n\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a description of the features.\nfeature_description = {\n    'item_A': tf.io.FixedLenFeature([], tf.int64),\n    'item_B': tf.io.FixedLenFeature([], tf.int64),\n    'rating': tf.io.FixedLenFeature([], tf.float32),\n    'ts': tf.io.FixedLenFeature([], tf.int64),\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert2string(element):\n    return {\"item_A\" : tf.strings.as_string(element['item_A']),\n            \"item_B\" : tf.strings.as_string(element['item_B']),\n            \"rating\" : element['rating'],\n            \"ts\"     : element['ts']}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    dataset = tf.data.Dataset.list_files(f'{TRAIN_DIR}/pptrain_chunk_*.tfrecord')\n    dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type='ZLIB'), block_length=1024, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.map(lambda x: tf.io.parse_single_example(x, feature_description),num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size=1024, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.map(convert2string)\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nwith strategy.scope():\n    items_dataset = tf.data.Dataset.load(ITEM_DIR)\n    items_dataset = items_dataset.batch(batch_size=1024,num_parallel_calls=tf.data.AUTOTUNE)\n    itemlist_unique = np.unique(np.concatenate(list(items_dataset)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A multitask Model\n\nThere are two critical parts to multi-task recommenders:\n\n* They optimize for two or more objectives, and so have two or more losses.\n* They share variables between the tasks, allowing for transfer learning.\nIn this tutorial, we will define our models as before, but instead of having a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches.\n\nThe user and movie models are as before:","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n    class item2itemModel(tfrs.models.Model):\n        def __init__(self) -> None:\n            super().__init__()\n            embedding_dimension = 32\n            self.item_A_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.item_B_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.rating_model = tf.keras.Sequential([\n                tf.keras.layers.Dense(256, activation=\"relu\"),\n                tf.keras.layers.Dense(128, activation=\"relu\"),\n                tf.keras.layers.Dense(1),\n                ])\n\n            self.retrieval_task = tfrs.tasks.Retrieval(\n                metrics=tfrs.metrics.FactorizedTopK(\n                    candidates=items_dataset.map(self.item_B_model),\n                    )\n                )\n\n            self.rating_task = tfrs.tasks.Ranking(\n                loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM),\n                metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                )\n\n        def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n            item_A_embeddings = self.item_A_model(features[\"item_A\"])\n            item_B_embeddings = self.item_B_model(features[\"item_B\"])\n            predicted_ratings = self.rating_model((tf.concat([item_A_embeddings, item_B_embeddings], axis=1)))\n            \n            return (item_A_embeddings, item_B_embeddings, predicted_ratings)\n\n        def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n            label_ratings = features.pop(\"rating\")\n            item_A_embeddings, item_B_embeddings, predicted_ratings = self(features)\n            rating_loss = self.rating_task(labels=label_ratings, predictions=predicted_ratings)\n            retrieval_loss = self.retrieval_task(item_A_embeddings, item_B_embeddings)\n\n            return (retrieval_loss + rating_loss)       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    class item2itemModelBase(tf.keras.Model):\n        def __init__(self) -> None:\n            super().__init__()\n            embedding_dimension = 32\n            self.item_A_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.item_B_model = tf.keras.Sequential([\n                tf.keras.layers.StringLookup(\n                    vocabulary=itemlist_unique, mask_token=None),\n                tf.keras.layers.Embedding(len(itemlist_unique) + 1, embedding_dimension)\n                ])\n\n            self.rating_model = tf.keras.Sequential([\n                tf.keras.layers.Dense(256, activation=\"relu\"),\n                tf.keras.layers.Dense(128, activation=\"relu\"),\n                tf.keras.layers.Dense(1),\n                ])\n\n            self.retrieval_task = tfrs.tasks.Retrieval(\n                metrics=tfrs.metrics.FactorizedTopK(\n                    candidates=items_dataset.map(self.item_B_model),\n                    )\n                )\n\n            self.rating_task = tfrs.tasks.Ranking(\n                loss=tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM),\n                metrics=[tf.keras.metrics.RootMeanSquaredError()],\n                )\n\n        def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n            item_A_embeddings = self.item_A_model(features[\"item_A\"])\n            item_B_embeddings = self.item_B_model(features[\"item_B\"])\n            predicted_ratings = self.rating_model((tf.concat([item_A_embeddings, item_B_embeddings], axis=1)))\n            return (item_A_embeddings, item_B_embeddings, predicted_ratings)\n\n        def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n            with tf.GradientTape() as tape:\n                label_ratings = features.pop(\"rating\")\n                item_A_embeddings, item_B_embeddings, predicted_ratings = self(features)\n                rating_loss = self.rating_task(labels=label_ratings, predictions=predicted_ratings, compute_metrics=False)\n                retrieval_loss = self.retrieval_task(item_A_embeddings, item_B_embeddings, compute_metrics=False)\n                regularization_loss = sum(self.losses)\n                total_loss = rating_loss + retrieval_loss + regularization_loss\n            gradients = tape.gradient(total_loss, self.trainable_variables)\n            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n\n            metrics={}\n            metrics[\"loss\"] = rating_loss + retrieval_loss\n            metrics[\"regularization_loss\"] = regularization_loss\n            metrics[\"total_loss\"] = total_loss\n            return metrics\n            \n        def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n            with tf.GradientTape() as tape:\n                label_ratings = features.pop(\"rating\")\n                item_A_embeddings, item_B_embeddings, predicted_ratings = self(features)\n                rating_loss = self.rating_task(labels=label_ratings, predictions=predicted_ratings, compute_metrics=False)\n                retrieval_loss = self.retrieval_task(item_A_embeddings, item_B_embeddings, compute_metrics=False)\n                regularization_loss = sum(self.losses)\n                total_loss = rating_loss + retrieval_loss + regularization_loss\n\n#             metrics = {metric.name: metric.result() for metric in self.metrics}\n            metrics={}\n            metrics[\"loss\"] = retrieval_loss\n            metrics[\"regularization_loss\"] = regularization_loss\n            metrics[\"total_loss\"] = total_loss\n            return metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = item2itemModelBase()\n    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith strategy.scope():\n#     train_dataset = dataset.shuffle(1000000, seed=42, reshuffle_each_iteration=False)\n    cached_train = dataset.cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath='/kaggle/working/chkpt1',\n        save_weights_only=True\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model.fit(cached_train, epochs=3, callbacks=[model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with strategy.scope():\n#     test_dataset = dataset.shuffle(1000, seed=42, reshuffle_each_iteration=False).take(100)\n#     cached_test = test_dataset.shuffle(100).cache()\n#     metrics = model.evaluate(cached_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     scann_index = tfrs.layers.factorized_top_k.ScaNN(model.item_A_model, k=20)\n#     scann_index.index_from_dataset(\n#       tf.data.Dataset.zip((items_dataset, items_dataset.map(model.item_B_model)))\n#     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     # Get recommendations.\n#     _, titles = scann_index(tf.constant([\"1585682\"]))\n#     print(f\"Recommendations for user 1585682: {titles[0, :10]}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Save the index.\n# tf.saved_model.save(\n#       scann_index,\n#       MODEL_DIR_SCAN,\n#       options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n#   )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.retrieval_task = tfrs.tasks.Retrieval()  # Removes the metrics.\n# model.compile()\n# model.save(MODEL_DIR_NORM)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r trainer.zip '/kaggle/working/serving_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r chkpt_1.zip '/kaggle/working/'","metadata":{},"execution_count":null,"outputs":[]}]}